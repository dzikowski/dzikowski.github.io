---
title: Miejsce Spark w technologiach big data
layout: post
description: |
    Spark wydaje mi się najbardziej wszechstronnym i, w większości przypadków, najlepszym narzędziem do analizy dużych zbiorów danych.
    Jak to często bywa w takich sytuacjach, zanim Spark powstał i stał się fajny, największe firmy zaczęły już korzystać z innych narzędzi (np. Hive i Pig).
    Tym razem jednak dzieje się coś dziwnego: zamiast ściśle trzymać się tego, co już dobrze znane, nawet te firmy w coraz większym stopniu korzystają ze Spark i znajdują dla niego nowe zastosowania.
---


Moim zdaniem można rozróżnić trzy główne podejścia do przetwarzania big data:

 1. Przetwarzania dużych zbiorów statycznych danych (tzw. _batch processing_), w tym operacje _Extract, Transform, Load_ (_ETL_) oraz analizy na żądanie (_ad hoc analysis_).
 2. Przetwarzanie strumieni danych (_stream processing_).
 3. Przetwarzanie dużych zbiorów danych w pamięci operacyjnej (_in-memory computing_).

W którym z tych obszarów mieści się Apache Spark?
Uwaga: **we wszystkich**.


Ogólnie o Spark
---

Celem Spark jest udostępnienie łatwego i uniwersalnego sposobu przetwarzania dużych, rozproszonych zbiorów danych.
Tradycyjne podejście -- MapReduce -- skaluje się bardzo dobrze, ale ma stosunkowo skomplikowane API, przez co tworzenie takich programów jest bardzo pracochłonne.
Spark rozdziela przetwarzanie danych na poszczególne zadania MapReduce, ale dzieje się to w tle.
Dzięki eleganckiemu i intuicyjnemu API, przetwarzanie _big data_ jest dużo łatwiejsze.

Centralną koncepcją Apache Spark są tzw. _resilient distributed datasets_, co można przetłumaczyć jako odporne na awarie, rozproszone kolekcje danych.
Istnieją one na wielu maszynach jednocześnie (na dyskach lub w pamięci operacyjnej), a w przypadku awarii są odtwarzane.

Na tych kolekcjach danych można przeprowadzać określone operacje, czyli -- zgodnie ze słownikiem Spark -- transformacje i akcje:

  - **Transformacje** (ang. _transformations_) polegają na przekształceniach obiektów (czyli operacje Map), filtrowaniu listy obiektów, albo grupowaniu.
    Transformacje są wykonywane dopiero wtedy, kiedy pojawi się akcja, która wymaga dostępu do przetworzonych danych (leniwa ewaluacja).
  - **Akcje** (_actions_) polegają np. na zliczaniu (czyli też z wszystkuim, co związane z operacją Reduce), zapisywaniu, albo wyświetlaniu przetworzonych danych.

Praca ze Spark polega po prostu na opisywaniu w zwięzły sposób operacji przetwarzania rozproszonych kolekcji danych.
Konieczne jest dostosowanie się do kilku reguł, ale elegancka składnia Spark i silna orientacja na dane pozwalają tworzyć programy znacznie bardziej czytelne niż skrypty Hive, czy Pig.

<!--- Jednocześnie Spark nie jest tak wyspecjalizowany, jak na przykład Hive. -->
Oprócz tego, Spark jest narzędziem uniwersalnym.
W łatwy sposób pozwala łączyć różnego typu operacje na danych: skrypty SQL, operacje ETL, uczenie maszynowe, obliczenia na grafach, czy przetwarzanie tekstu.

Wreszcie, należy wspomnieć o bardzo wyskiej wydajności.
W listopadzie 2014 roku Spark [pobił rekord](http://databricks.com/blog/2014/11/05/spark-officially-sets-a-new-record-in-large-scale-sorting.html) wydajności sortowania 100 petabajtów danych (1&nbsp;PB&nbsp;=&nbsp;1&nbsp;000&nbsp;000&nbsp;TB), wykonując tę czynność w 23 minuty na -- ponad 3 razy szybciej niż Hadoop MapReduce (i to bez wykorzystywania wszystkich możliwości optymalizacji wydajności Spark).

Na tak wysoką wydajność Spark wpływają przede wszystkim dwa czynniki.
Po pierwsze, leniwe wykonywanie transformacji i optymalizacja sekwencji tranformacji, dzięki czemu minimalizowana jest ilość koniecznych do wykonania operacji na danych, oraz operacji odczytu i zapisu na dysku.
Po drugie, możliwość tymczasowego zapisywania rezultatów w pamięci podręcznej (ang. _cache_), co także prowadzi do zminimalizowania odczytu i zapisu danych na dysku.
Dzięki temu w Spark można nawet wykonywać iteracyjne algorytmy uczenia maszynowego, co bez takich optymalizacji -- w klasycznym MapReduce, Hive, czy Pig -- byłoby nie do pomyślenia.

Oczywiście Spark ma niewielkie wady.
Zanim jednak do nich przejdę, zacznę od porównania Spark z innymi uznanymi narzędziami big data.



Spark vs Pig
---

Jednym z popularniejszych rozwiązań do przetwarzania big data wydaje się być [Apache Pig](http://pig.apache.org/), które umożliwia tworzenie skryptów w specjalnym języku, Pig Latin, i wykonywanie ich w środowisku rozproszonym.
Pig zostało stworzone około 2006 roku przez Yahoo!, a w roku 2007 stało się projektem Open Source pod skrzydłami Apache Foundation.

Pig dobrze nadaje się do przetwarzania danych, jednak mimo tego, że ma już swoje lata, ciągle jest narzędziem stosunkowo wolnym.
Dopiero od niedawna Hortonworks dostarcza Pig zintegrowane z Tez, a Sigmoid Analitics, zamiast Tez jako silnika optymalizacji dla Pig, wykorzystuje... Spark.

Oprócz kilku istotnych zalet (odporność na błędy i obsługa wielu formatów danych, dobre wsparcie, integraja z platformami Hortonworks i Cloudera), Pig ma jednak jedną wadę, która przyćmiewa wszystko inne: skrypty w Pig są niesamowicie brzydkie.
Nie jest tu oczywiście problemem moje poczucie estetyki, ale ich nieczytelność.

Poniżej zamieszczam przyklad zliczania słów, napisany w Pig Latin (z [Wikipedii](http://en.wikipedia.org/wiki/Pig_%28programming_tool%29#Example)).

{% highlight pig %}
input_lines = LOAD '/tmp/my-copy-of-all-pages-on-internet' AS (line:chararray);

-- Extract words from each line and put them into a pig bag
-- datatype, then flatten the bag to get one word on each row
words = FOREACH input_lines GENERATE FLATTEN(TOKENIZE(line)) AS word;

-- filter out any words that are just white spaces
filtered_words = FILTER words BY word MATCHES '\\w+';

-- create a group for each word
word_groups = GROUP filtered_words BY word;

-- count the entries in each group
word_count = FOREACH word_groups GENERATE COUNT(filtered_words) AS count, group AS word;

-- order the records by count
ordered_word_count = ORDER word_count BY count DESC;
STORE ordered_word_count INTO '/tmp/number-of-words-on-internet';
{% endhighlight %}

Programowanie jest sposobem komunikowania się.
Jeśli nowa osoba, znająca Pig i Spark, otrzymałaby do analizy po jednym skrypcie z każdego z tych dwóch narzędzi, a skrypty robiłyby dokładnie to samo, to zapoznanie się z wersją w Spark, zajęłoby zdecydowanie mniej czasu.

Język Pig Latin pełen jest sprzeczności i niekonsekwencji.
Niektóre elementy muszą być pisane zawsze wielkimi literami (np. funkcja ```SUM```), niektóre mogą być pisane albo małymi, albo wielkimi (np słowa kluczowe ```LOAD```, albo ```GENERATE```).
Sam język jest imperatywny, ale miejscami widać mocną inspirację deklaratywnym SQL.
Pewnym problemem może być także brak kontroli typów i trochę bardziej zaawansowanych konstrukcji języka, np. tradycyjnie rozumianej instrukcji warunkowej, albo struktur danych.

Wszystko to sprawia, że utrzymanie i rozbudowa skryptów Pig -- mimo że łatwiejsze, niż skryptów Hive -- nie jest wcale proste.



Spark vs Scalding
---

Inne podejście do przetwarzania statycznych danych w środowisku rozproszonym reprezentuje [Cascading](http://www.cascading.org/).
Powstaniu Cascading przyświecał podobny cel, jak Spark i Pig -- umożliwienie przetwarzania big data, ukrywając jednocześnie złożoność MapReduce.
Projekt został wykorzystany przez Twittera, który stworzył do Cascading zgrabne API w Scali i w 2012 roku je upublicznił.
Tak powstał projekt [Scalding](https://github.com/twitter/scalding/wiki).

Cascading i Scalding są łatwiejsze w użyciu niż MapReduce (Scalding nawet o wiele łatwiejszy), a przy tym dają możliwości, których w Pig nie ma: możliwość wykorzystania bogactwa struktur popularnego języka programowania (a nie hermetycznego, dedykowanego, jak Pig Latin), możliwość kontroli typów, czy -- co chyba najważniejsze -- pisania testów jednostkowych.

Trzeba przyznać, że przykład zliczania słów w Scalding (z oficjalnej [dokumentacji](https://github.com/twitter/scalding/wiki/Type-safe-api-reference) projektu), wygląda dużo lepiej niż w Pig:

{% highlight scala %}
class WordCountJob(args : Args) extends Job(args) {
  TypedPipe.from(TextLine("/path/to/input-file"))
    .flatMap(line => line.split("""\s+"""))
    .groupBy(word => word)
    .size
    .write(TypedTsv("/path/to/output-file"))
}
{% endhighlight %}

Albo przykład uproszczony:

{% highlight scala %}
class WordCountJob(args : Args) extends Job(args) {
  TypedPipe.from(TextLine("/path/to/input-file")))
    .flatMap(_.split("\\s+"))
    .group
    .sum
    .write(TypedTsv("/path/to/output-file"))
}
{% endhighlight %}


Dla porównania przykład w Spark, który zadziała niemal identycznie:

{% highlight scala %}
val spark = new SparkContext(new SparkConf().setAppName("WordCount"))

spark.textFile("/path/to/input-file")
  .flatMap(line => line.split("""\s+"""))
  .map(word => (word, 1))
  .reduceByKey(_ + _)
  .saveAsTextFile("/path/to/output-file")
{% endhighlight %}

Zliczanie słów w Scalding i Spark wyglądają bardzo podobnie.
Jedną z przyczyn takiego stanu rzeczy jest po prostu to, że w obu przypadkach wykorzystywany jest potencjał języka programowania Scala, w który operacje Map i Reduce są w zasadzie wbudowane.

Tym, czego może nie widać jeszcze na powyższych przykładach (ale co dobrze widać [tutaj](http://mlnick.github.io/blog/2013/04/01/movie-recommendations-and-more-with-spark/)), jest nieco inna filozofia obu projektów.
Spark jest narzędziem bardzo ogólnym, natomiast Scalding wydaje się bardziej przystosowany do operacji na danych tabelarycznych.
To często powoduje, że kod w Scalding jest znacznie krótszy niż w Spark w przypadku manipulacji wieloma kolumnami danych, czy też przy wczytywaniu i zapisywaniu plików CSV/TSV.
W takich zastosowaniach Scalding wydawałby się lepszy... gdyby nie kwestia wydajności.
Ostatnio nawet Twitter upublicznił [prezentację](http://www.slideshare.net/krishflix/seattle-spark-meetup-spark-at-twitter), pokazującą większą wydajność Spark.

Poza tym Scalding nie nadaje się do przetwarzania strumieni danych i brakuje w nim interaktywnej konsoli.



Spark vs Hive
---

Hive zostało stworzone przez Facebooka, ale aktywnie wspierają je też takie firmy, jak Amazon i Netflix.
Hive pozwala na wykonywanie zapytań na danych w języku Hive QL, który jest bardzo podobny do SQL.
Co się z tym wiąże, ma wszystkie wady i zalety języka SQL.

Najlepiej się nadaje do analizy statycznych danych tabelarycznych, a nawet -- w przypadku zastosowania własnych formatów interpretacji danych, tzw. SerDe -- analizy plików, tak jakby były tabelami.
W Hive można zdefiniować takie SerDe, że nawet nie pliki TSV, ale katalogi z plikami XML lub JSON, mogą być traktowane jako tabele danych i odpytywane w Hive jako tabele.

Inną znaczącą zaletą, której też nie ma Spark, jest optymalizacja przechowywania tabel, pozwalająca na szybszą pracę z danymi (por. PARTITIONED BY i SKEWED BY z oficjalnej [dokumentacji](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)), albo próbkowanie i rodzielanie danych do tzw. _buckets_, co jest bardzo przydatne w efektywnej analizie big data.

Zaletą jest także w zasadzie brak konieczności uczenia się nowego języka w przypadku analityków danych, znających SQL.
Osoby pracujące do tej pory na standardowych hurtowniach danych łatwo powinny się przestawić na Hive.

W tym momencie znów należy wskazać uniwersalność Spark, jednakże tutaj może ona być traktowana jako wada.
Hive za to nie nadaje się do przeprowadzania skomplikowanych analiz na danych (np. wymagających analizy trendów, albo uczenia maszynowego); nie nadaje się także do operacji ETL.
Jest po prostu narzędziem bardzo wyspecjalizowanym i do tego, do czego zostało stworzone, nadaje się świetnie.

Przykład zliczania słów w Hive (ze [StackOverflow](http://stackoverflow.com/questions/10039949/word-count-program-in-hive)):

{% highlight sql %}
SELECT word, COUNT(*) 
FROM input LATERAL VIEW explode(split(text, ' ')) lTable AS word 
GROUP BY word;
{% endhighlight %}

Potencjał Hive oczywiście został odkryty przez społeczność Apache Spark.
Kiedy powstał Spark, Hive było jedynym (i mało wydajnym) narzedziem, które umożliwiało wywoływanie zapytań (podobnych do) SQL w środowisku rozproszonym.
Potem społeczność Spark stworzyła projekt Shark, który rónież umożliwiał wywoływanie zapytań SQL, ale dzięki temu, że Shark działał na Spark, a nie na MapReduce, jak Hive, był od niego dużo bardziej wydajny.
Shark jednak odziedziczył mnóstwo trudnego w utrzymaniu kodu zaczerpniętego z Hive, co ostatecznie doprowadziło do sytuacji, w której Shark przestał być rozwijany, na rzecz podprojektu Spark: Spark SQL.
Spark SQL jest uznawany za wydajniejszy niż Shark (zgodnie z [tym artykułem](http://databricks.com/blog/2014/06/02/exciting-performance-improvements-on-the-horizon-for-spark-sql.html)) i w większości jest kompatybilny z Hive (zgodnie z [tym artykułem](http://databricks.com/blog/2014/07/01/shark-spark-sql-hive-on-spark-and-the-future-of-sql-on-spark.html)).

Natomiast aby zwiększyć wydajność samego Hive, w tej chwili działają dwie główne inicjatywy.
Pierwszą forsuje Hortonworks: silnikiem wykonywania skryptów Hive ma już nie być MapReduce, ale Tez.
Druga wyszła ze społeczności Hive i jest wspierana przez Clouderę: silnikiem wykonywania skryptów Hive ma być... Spark.


Spark vs Tez
---

Relacja pomiedzy Spark i Tez na pierwszy rzut oka wydaje się odległa, jednak przy bliższym spojrzeniu okazuje się, że mają wiele wspólnego.
Mają przede wszystkim takie same korzenie i podobną filozofię działania.
Mimo że powstały w innych celach, to zarówno Spark i Tez znajdują zastosowanie jako silniki wykonywania skryptów Pig i Hive.

Pisałem już o obu narzedziach w [tym poście](http://dzikowski.github.io/2014/12/18/spark-czy-tez/).


Spark vs Storm
---

Spark Streaming i Storm służą do podobnych zadań, choć ujmują problem przetwarzania strumieni danych w całkiem inny sposób.
Spark został stworzony jako ogólne narzędzie do przetwarzania danych w środowisku rozproszonym, początkowo były to dane statyczne.
Z czasem powstał Spark Streaming, rozwiązanie, które wykonywało tzw. _micro-batching_: transformacje i akcje Spark przeprowadzane były co kilka sekund na nowo pojawiających się danych.

Storm powstał w firmie BackType, która została przejęta przez Twitter, który z kolei w 2011 roku wypuścił Storm jako projekt Open Source.
W tej chwili jest wykorzystywany w takich firmach, jak Twitter, Yahoo!, czy Spotify.

Idea, która stoi za Storm jest nieco inna niż ta, która stoi za Spark.
Storm powstał od razu jako narzędzie wyspecjalizowane w przetwarzaniu strumieni danych.
Stąd też specyficzna terminologia i architektura odbiegająca od podejścia MapReduce.

Podstawowe pojęcia to topologia (ang. _topology_), _spout_ i _bolt_.
Przetłumaczenie dwóch ostatnich na język polski nastręcza sporo trudności ([1](https://translate.google.pl/?ie=UTF-8&hl=pl&client=tw-ob#en/pl/spout) i [2](https://translate.google.pl/?ie=UTF-8&hl=pl&client=tw-ob#en/pl/bolt)).

Topologia to graf skierowany, w którym krawędzie określają przepływ danych, a wierzchołki to _spouts_ i _bolts_.
_Spout_ to źródło danych, _bolt_ to miejsce, w którym dane są przetwarzane.
Przetwarzane i przesłane dane mają postać strumieni krotek (ang _tuples_).

Topologia może mieć taką postać ([źródło](http://realtime-cachedmind.tumblr.com/post/89974796387/real-time-processing-storm-trident-vs)):

![Topologia](http://media.tumblr.com/a49e27cdd590279c0baab52c06f91441/tumblr_inline_n7z4x4nqt11sife9u.png)

Storm przetwarza dane od razu, krotka po krotce, dopiero rozwinięcie Storm -- Storm Trident, przeprowadza _micro-batching_, który jest czymś podobnym do tego ze Spark Streaming (i przy okazji daje też lepsze gwarancje dostarczania danych, ale o tym będzie we wpisie dedykowanym Storm).
Jednak ten model przetwarzania jest całkiem inny, niż w klasycznym Storm.

Przede wszystkim podejście w klasycznym Storm daje gwarancję dostarczenia komukatu (krotki) przynajmniej raz do danego _bolt_, co oznacza, że może dojść do tego, że jakiś komunikat trafi do danego _bolt_ dwukrotnie.
Spark Streaming natomiast gwarantuje przetworzenie danych dokładnie jeden raz (choć podobno istnieją takie scenariusze awarii klastra, które podważają taką gwarancję).

Trudno powiedzieć, czy działa to na korzyść Spark, czy też mamy remis.
Zdecydowanie na korzyść Storm przemawia jednak kolejny punkt: (latencja, ang. _latency_).

Latencja, czy też opóźnienie, to ważny aspekt w przetwarzaniu strumieni danych, gdzie najlepiej, by wszystko działo się jednocześnie.
Tymczasem podejście zastosowane w Spark Streaming, _micro-batching_, wymusza większe opóźnienie, niż topologie Storm.
W Storm znacznie łatwiej dość do przetwarzania nowych komunkatów w strumieniu danych w czasie mniejszym niż sekunda, podczas gdy w Spark Streaming standardem jest kilka sekund.

Zderzenie Spark i Storm, to zderzenie uniwersalności ze specjalizacją.
Spark może ma większe wsparcie i jest powszechniej wykorzystywany, jednak dla niektórych rozwiązań znacznie lepiej nadają się dedykowane rozwiązania, takie jak Apache Storm.


Spark vs Summingbird
---

Często wskazywaną zaletą Spark jest to, że używa się takiej samej logiki do przetwarzania danych statycznych i do przetwarzania strumieni danych.
Dzięki temu nie trzeba duplikować kodu.
Jeśli logika przetwarzania danych zostanie prawidłowo odseparowana, ten sam kod może być wykorzystany w jednym i drugim przypadku.

Rozwijający własne narzędzia big data Twitter doszedł do podobnego wniosku.
W Twiterze wykorzystywane są Scalding i Storm, które narzucają konieczność programowania w całkiem innych podejściach.
Dlatego powstał [Summingbird](https://github.com/twitter/summingbird).

Summingbird pozwala na opisywanie przetwarzania danych w ramach standardowych konstrukcji języka Scala, dorzuca tylko kilka własnych instrukcji.
Ale dzięki temu, że przetwarzanie danych zostało zdefiniowane z wykorzystaniem Summingbird, można ten sam kod wykonać w różnych trybach:

  * Jako _batch processing_, gdzie napisany program będzie wywołany na Scalding.
  * Jako _stream processing_, gdzie ten sam program będzie wywołany jako topologia Storm.
  * W trybie hybrydowym, jednocześnie na Scalding i Storm, co pozwala na efektywne przetwarzania dużych, ciągle zmieniających się zbiorów danych (i to jest nisza, której Spark wydaje się nie wypełniać).

Tym samym Summingbird, podobnie jak Spark, dostarcza uniwersalny model programowania, jednak korzysta np. ze Scalding, który jest mniej wydajny.
Stąd też [plany](https://github.com/twitter/summingbird/wiki#future-plans) i pierwsze [przymiarki](https://github.com/twitter/summingbird/tree/develop/summingbird-spark) Twittera, żeby umożliwić wykonywanie programów Summingbird nie tylko na Scalding, ale też na Spark.
Jak to zadziała w praktyce?
Zobaczymy.


Czy Spark ma wady?
---

Oczywiście, ale takie mało znaczące, że muszę wymyślać je niemal na siłę.
(Albo jestem takim zaślepionym zwolennikiem Apache Spark, że nie widzę ich wyraźnie).

Rozwiązania, które są na rynku już stosunkowo długo (jak na big data), czyli Pig i Hive doczekały się narzędzi, ułatwiających pisanie i wywoływanie skryptów.
Można to robić bezpośrednio w aplikacji Hue, będącej interfejsem WWW do klastra Hadoop, znajdującej się w dwóch najpopularniejszych platformach -- [Cloudera](http://www.cloudera.com/content/cloudera/en/products-and-services/cdh.html) i [Hortonworks](http://hortonworks.com/hdp/).
Tym samym, aby wykonywać obliczenia w środowisku rozproszonym w Hive i Pig, nie jest konieczna instalacja żadnego dodatkowego oprogramowania, wystarczy przeglądarka internetowa i dostęp do Hue.
Spark jeszcze nie doczekał się takiego interfejsu, co sprawia, że ciągle nadaje się bardziej dla programisty niż analityka.

Pewną wadą Spark może być też technologia, w której został stworzony.
Nie da się ukryć, że dopiero w Javie 8 Spark jest porównywalnie zwięzły, jak Spark w Scali i Pythonie.
W starszych wersjach Javy trzeba tworzyć specjalne obiekty i klasy na funkcje, co powoduje, że proste przekształcenie z jednej linijki może rozrosnąć się do kilkunastu (i wynika to wyłącznie z braku wsparcia Javy dla wyrażeń Lambda).

Python nie ma pełnego wsparcia w Spark (do niedawna jeszcze nie można było korzystać ze Spark Streaming w Pythonie), a Scala, mimo nadzwyczajnej ekspresyjności i zgodności z JVM, ciągle jest mało popularna.
Innymi słowy, kolejną przeszkodą, może być bariera językowa.

Wreszcie drobną wadą Spark może być jego ogólność.
Takie narzędzia jak Hive, czy Storm, właśnie dzięki temu, że są wyspecjalizowane, do części zadań nadają się lepiej niż Spark.


Przyszłość
---

... zdecydowanie należy do Apache Spark, choć trudno powiedzieć, jaka.
W zasadzie teraźniejszość też już jest nim silnie naznaczona.
Nie przewiduję, że wyparte zostanią takie wyspecjalizowane i świetnie się sprawdzające rozwiązania, jak Hive, Storm, czy Scalding.
Pewnie nawet siermiężne Pig tak szybko nie upadnie, bo wiele skryptów Pig działa od dawna i nie ma większego powodu, żeby się ich pozbywać.
Pewnie analitycy w dalszym ciągu nie będą (bezpośrednio) korzystać ze Spark, który wśród programistów już teraz ma duże uznanie.
Kilka lat młodszy od znanych narzędzi, bardzo szybko znalazł sobie znaczące miejsce w środowisku big data i powinien je w dalszym ciągu umacniać.

Jako pewne ryzyko można rozpatrywać jedną z największych zalet Spark -- jego uniwersalność.
Może się oczywiście zdarzyć, że powstanie mnóstwo wyspecjalizowanych rozwiązań i każde z nich zabierze Spark część rynku, jednak wydaje mi się to mało prawdopodobne.
Historia pokazała, że jeśli jakies rozwiązanie jest wydajne i uniwersalne, szybko zyskuje użytkowników, a główną barierą jest najwyżej zjawisko zwane _[vendor lock-in](http://en.wikipedia.org/wiki/Vendor_lock-in)_.
To samo zjawisko, przez które rynek jeszcze nie porzucił Pig i wielu innych narzędzi.

Jednak i tutaj wydaje się, że Spark znajduje sobie niszę.
Skoro wykorzystywane są już rozwiązania bazujące na Hive, Pig, czy Summingbird, i te rozwiązania działają wolno, wydajny Spark służy jako silnik, na którym mogą być uruchamiane te narzędzia.
Wtedy bezpośrednim konkurentem staje się Tez, który ma tę wadę, że... jest mniej uniwersalny.




Do poczytania
---

Dzisiejsza sekcja "Do poczytania" jest dużo bardziej obszerna niż zawsze, ponieważ pojawiły się informacje o wielu nowych narzędziach.
Wpis był eklektyczny, dotyczył wielu różnych narzędzi, dlatego poniżej prezentuję odnośniki, z których korzystałem i które mogą Ci pozwolić poszerzyć wiedzę z zakresu narzędzi big data.

### Apache Spark

  * [Artykuł](http://radar.oreilly.com/2013/02/the-future-of-big-data-with-bdas-the-berkeley-data-analytics-stack.html) opisujący motywację twórców Apache Spark.
  * Główna [strona](https://spark.apache.org/) projektu Apache Spark.
    Zawiera między innymi użyteczne przykłady w Scali, Pythonie i Javie.
  * [Wprowadzenie](http://www.pentaho.com/sites/default/files/uploads/resources/learning_spark_preview_ed.pdf) do Spark -- wersja robocza pierwszego rozdziału książki "[Learning Spark](http://shop.oreilly.com/product/0636920028512.do)" wydawnictwa O'Reilly.
  * [Wpis](http://stackoverflow.com/questions/24762672/how-does-apache-spark-handles-system-failure-when-deployed-in-yarn) na StackOverflow o tym, w jaki sposób Spark radzi sobie z obsługą awarii.
  * Obszerne zasoby szkoleniowe na [stronie](http://databricks.com/spark-training) Databricks, dostarczającej platformę big data, opierającą się głównie na Spark.
    Na tej stronie można znaleźć odnośniki do wielu prezentacji z warszatatów ze Spark, a także odnośniki do darmowych kursów online ze Spark.
  * Inny punkt widzenia: [prezentacja](http://www.slideshare.net/krishflix/seattle-spark-meetup-spark-at-twitter) Twittera (wykorzystującego Pig oraz Summingbird + Scalding + Storm) o tym, jakie może mieć zalety przejście na Spark.
    Prezentacja zawiera także porównanie wydajności Spark z Pig i Scalding.

### Pig

  * Główna [strona](http://pig.apache.org/) projektu Apache Pig.
  * [Przewodnik](https://cs.uwaterloo.ca/~kmsalem/courses/CS848W10/presentations/Welch-PigLatin.pdf) z przykładami.
  * Przystępny [opis](http://bugra.github.io/work/notes/2014-02-08/pig-advantages-and-disadvantages/) zalet i wad Pig.
  * Książka "[Programming Pig](http://chimera.labs.oreilly.com/books/1234000001811/index.html)" dostępna za darmo, napisana przez Alana Gatesa z Yahoo!.

### Scalding

  * Główna [strona](https://github.com/twitter/scalding) projektu Twitter Scalding.
  * [Porównanie](http://tech.blog.box.com/2014/07/evaluating-apache-spark-and-twitter-scalding/) wydajności Spark vs Scalding (z lipca 2014).
  * [Porównanie](http://mlnick.github.io/blog/2013/04/01/movie-recommendations-and-more-with-spark/) przykładów kodu Scalding i Spark.

### Hive
  * Główna [strona](https://hive.apache.org/) projektu Apache Hive.
  * [Artykuł](http://blog.cloudera.com/blog/2014/11/apache-hive-on-apache-spark-the-first-demo/) Cloudery o Hive na Spark, [instrukcja](https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started) uruchamiania Hive na Spark.
  * [Informacje](http://databricks.com/blog/2014/07/01/shark-spark-sql-hive-on-spark-and-the-future-of-sql-on-spark.html) projekcie Spark SQL i jego relacji do Shark.

### Storm

  * Główna [strona](https://storm.apache.org/) projektu Apache Storm, w tym [omówienie](https://storm.apache.org/documentation/Tutorial.html) najważniejszych pojęć i architektury.
  * [Wpis](https://blog.twitter.com/2011/storm-coming-more-details-and-plans-release) o Storm na bloku Twittera.
  * [Wytłumaczenie](http://www.michael-noll.com/blog/2012/10/16/understanding-the-parallelism-of-a-storm-topology/) tego, w jaki sposób działa przetwarzanie rozproszone w Storm.
  * [Porównanie 1](http://www.zdatainc.com/2014/09/apache-storm-apache-spark/), [porównanie 2](http://www.slideshare.net/ptgoetz/apache-storm-vs-spark-streaming) i [porównanie 3](http://xinhstechblog.blogspot.com/2014/06/storm-vs-spark-streaming-side-by-side.html) Apache Spark z Apache Storm.
  
### Summingbird

  * Główna [strona](https://github.com/twitter/summingbird) projektu Twitter Summingbird.
  * Jak powstał i do czego służy Summingbird -- [wpis](https://blog.twitter.com/2013/streaming-mapreduce-with-summingbird) na blogu Twittera.
  * [Artykuł](http://www.vldb.org/pvldb/vol7/p1441-boykin.pdf) opisujący kompleksowo, jak działa Summingbird i jakie są jego powiązania ze Scalding i Storm.
  
  
Dodatkowo polecam też stosunkowo stare, ale i tak zawierające sporo ciekawych informacji [porównanie](http://blog.samibadawi.com/2012/03/hive-pig-scalding-scoobi-scrunch-and.html) Pig, Scalding, Hive, Spark i innych narzędzi.

